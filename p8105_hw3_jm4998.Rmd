---
title: "P8105 Homework 3"
author: "Junhui Mi"
date: "2019/10/8"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%")

library(tidyverse)
library(ggridges)

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d

theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

# Problem 1
### 0)
```{r}
library(p8105.datasets)
data("instacart")
instacart %>%
  head(3) %>%
  knitr::kable()
```

Description of the dataset:

The Instacart dataset is an online grocery shopping dataset in 2017. The dataset instacart contains `r length(instacart)` variables and `r length(pull(instacart, order_id))` observations. Some key variables are: "product_name", "aisle", "order_id", "user_id", "order_dow", "order_hour_of_day".

Use the first there rows as an example: We can see that customer with user_id 112108 bought "Bulgarian Yogurt", "Organic 4% Milk Fat Whole Milk Cottage Cheese" and "Organic Celery Hearts" at 10:00 in the morning.


### 1)
```{r}
instacart %>%
  group_by(aisle) %>%
  summarize(n = n()) %>%
  arrange(desc(n)) %>%
  head(1) %>%
  knitr::kable()

instacart %>%
  distinct(aisle) %>%
  nrow()
```

There are 134 aisles, and "fresh vegetables" are the most items ordered from.

### 2)
```{r}
instacart %>%
  group_by(aisle) %>%
  summarize(n = n()) %>%
  filter(n > 10000) %>%
  ggplot(aes(x = reorder(aisle, n), y = n)) + 
  geom_col(fill = "blue") + 
  labs(
    title = "Plot of Aisles Order Number",
    x = "Aisles",
    y = "Number of items ordered",
    caption = "Data from instacart") +
  coord_flip()
```

Above is a plot that shows the number of items ordered in each aisle, limiting to aisles with more than 10000 items ordered. There are 39 such aisles. Ranking the top 3 are "fresh vegetables", "fresh fruits", "packaged vegetables fruits".

### 3)
```{r}
instacart %>%
  filter(aisle %in% c("baking ingredients", "dog food care", 
                      "packaged vegetables fruits")) %>%
  group_by(aisle, product_name) %>%
  summarize(number_of_selling = n()) %>%
  arrange(desc(number_of_selling)) %>%
  top_n(3) %>%
  knitr::kable(caption = "Three most popular products",
               col.names = c("Product category", "Product name",
                             "Number of selling"))
```

Above is a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”.

The three most popular items in “baking ingredients” are "Light Brown Sugar", "Pure Baking Soda", "Cane Sugar". The three most popular items in “dog food care” are "Snack Sticks Chicken & Rice Recipe Dog Treats", "Organix Chicken & Brown Rice Recipe", "Small Dog Biscuits". The three most popular items in “packaged vegetables fruits” are "Organic Baby Spinach", "Organic Raspberries", "Organic Blueberries".

The most popular items in “packaged vegetables fruits” have large numbers of selling compared to the most popular items in “dog food care”.

### 4)
```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(meantime_of_selling = mean(order_hour_of_day)) %>%
  pivot_wider(
    names_from = order_dow,
    values_from = meantime_of_selling
  ) %>%
  knitr::kable(caption = "Mean Order time of two product", 
               col.names =
                 c("Product Name", "Sunday", "Monday", "Tuesday",
                   "Wednesday", "Thursday", "Friday", "Saturday"),
               digits = 0)
```

Above is a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week. We can conclude that the main order time of the two products are between 11:00 and 15:00.

# Problem 2
### 0)
```{r}
library(p8105.datasets)
data("brfss_smart2010")
brfss_ordered = brfss_smart2010 %>%
  janitor::clean_names() %>%
  filter(topic == "Overall Health",
         response %in% c("Excellent","Very good", "Good","Fair","Poor")) %>%
  mutate(response = forcats::fct_relevel(response, 
                                        c("Poor", "Fair", "Good", 
                                          "Very good","Excellent")))
```

Firstly, we do some cleaning on BRFSS data and focus on the “Overall Health” topic.

### 1)
```{r}
brfss_ordered %>%
 filter(year == 2002) %>%
  group_by(locationabbr, locationdesc) %>%
  summarize(n = n()) %>%
  group_by(locationabbr) %>%
  summarize(observed_locations_2002 = n()) %>%
  filter(observed_locations_2002 >= 7) %>%
  knitr::kable(caption = "Table 2002")
```

In 2002, there were 6 states (CT, FL, MA, NC, NJ, PA) observed at 7 or more locations.

```{r}
brfss_ordered %>%
 filter(year == 2010) %>%
  group_by(locationabbr, locationdesc) %>%
  summarize(n = n()) %>%
  group_by(locationabbr) %>%
  summarize(observed_locations_2010 = n()) %>%
  filter(observed_locations_2010 >= 7) %>%
  knitr::kable(caption = "Table 2010")
```

In 2010, there were 14 states (CA, CO, FL, MA, MD, NC, NE, NJ, NY, OH, PA, SC, TX, WA) observed at 7 or more locations. The number of states increased and the number of observed locations in each state increased as well compared to 2002.

### 2)
```{r}
brfss_average = brfss_ordered %>%
  filter(response == "Excellent") %>%
  group_by(year, locationabbr) %>%
  summarize(average_value = mean(data_value, na.omit = TRUE))
brfss_average %>%
  mutate(state = locationabbr) %>%
  ggplot(aes(x = year, y = average_value, color = state)) + 
    geom_point() + geom_line() + 
  labs(title = "Average value between 2002 and 2010 within state",
       caption = "Data from BRFSS")
```

The “spaghetti” plot above shows the average value between 2002 and 2010 within states. We can see that in year 2005, 2007 and 2009, most states experienced downs.

### 3)
```{r}
brfss_ordered %>%
  filter(year %in% c(2006, 2010),
         locationabbr == "NY") %>%
  mutate(county = locationdesc) %>%
  ggplot(aes(x = response, y = data_value, fill = county)) +
  geom_bar(stat = "identity", position = "dodge", width = 0.5) +
  facet_grid(~year) + 
  viridis::scale_fill_viridis(discrete = TRUE) +
  labs(title = "Distribution of responses among counties in NY State",
       caption = "Data from BRFSS")
```

The two-panel plot above shows the distribution of data_value for responses among locations in NY State in 2006 and 2010. We can see that in 2010, more counties such as Bronx and Erie were included. The value of "very good" also had a significant increase in year 2010.

# Problem 3
### 1)
```{r}
accel_data = read_csv("./dataset/accel_data.csv") %>%
  janitor::clean_names() %>%
  mutate(
    weekday_weekend = case_when(
    day %in% c("Saturday", "Sunday") ~ "weekend",
    day %in% c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday")
    ~ "weekend",
    TRUE ~ ""),
    day = factor(day, 
                 levels = c("Monday", "Tuesday", "Wednesday", "Thursday",
                            "Friday", "Saturday", "Sunday"))) %>%
  pivot_longer(
    starts_with("activity_"),
    names_to = "minute", 
    names_prefix = "activity_",
    values_to = "counts"
  ) %>%
  mutate(minute = factor(minute, levels = c(1:1440)))
```

Description of the dataset:

The accel_data contains five weeks of accelerometer data collected on a 63 year-old male with BMI 25. The dataset accel_data has `r length(accel_data)` variables and `r length(pull(accel_data, day_id))` observations. The existing variables are : `r colnames(accel_data)`. Key variables are: "week", "day", "minute" and "counts".

### 2)
```{r}
accel_data %>%
  group_by(week, day) %>%
  summarize(total_activity = sum(counts)) %>%
  knitr::kable(caption = "Total activity for each day")

accel_data %>%
  group_by(week, day) %>%
  summarize(total_activity = sum(counts)) %>%
  ggplot(aes(x = week, y = total_activity, color = day)) +
    geom_point() + geom_line() +
  labs(title = "Total activity for each day",
       caption = "Data from Columbia University Medical Center")
```

We can conclude from the table and plot above that:

1)The man's total activity did not fluctuate too much on Tuesday, Wednesday and Thursday probably due to routine work.

2)The man's total activity fluctuated a lot on Monday, Friday, Saturday and Sunday.

3)The man's total activity was extremely low on Saturdays in week 4 and 5. Probably he just stayed at home and did nothing. 

### 3)
```{r}
accel_data %>%
  arrange(week, day) %>%
  ggplot(aes(x = minute, y = counts, color = day)) +
  scale_x_discrete(
    breaks = seq(0,1440,60), 
    labels = as.character(c(0:24))) +
    geom_point() + geom_line() + 
  viridis::scale_fill_viridis(discrete = TRUE) +
  labs(title = "24-hour activity time courses",
       x = "Hours",
       y = "Activity Counts",
       caption = "Data from Columbia University Medical Center")
```

The plot above shows the man's 24-hour activity time courses and we can clearly see that:

1) The man usually gets up around 6 during weekdays and a bit late during weekends.

2) The man usually exercises between 19 and 22 in the evening, and then goes to sleep after 22pm.

3) The man usually has a lot of activities on Sunday noon, Saturday afternoon and Friday evening.